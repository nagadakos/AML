{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/nikolaos/Workspaces/AML/Assignment_1_Programming/code/lib_liblinear/python', '/home/nikolaos/.virtualenvs/nlp/lib/python36.zip', '/home/nikolaos/.virtualenvs/nlp/lib/python3.6', '/home/nikolaos/.virtualenvs/nlp/lib/python3.6/lib-dynload', '/usr/lib/python3.6', '', '/home/nikolaos/.virtualenvs/nlp/lib/python3.6/site-packages', '/home/nikolaos/.virtualenvs/nlp/lib/python3.6/site-packages/IPython/extensions', '/home/nikolaos/.ipython']\n",
      "/home/nikolaos/Workspaces/AML/Assignment_1_Programming/code\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import lib_liblinear.python.liblinearutil as lbl\n",
    "\n",
    "\n",
    "dir_path = Path.cwd()\n",
    "\n",
    "print(dir_path)\n",
    "sys.path.insert(0, dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading! Sizes are X: (12800,), W:(3328,),T: (676,)\n"
     ]
    }
   ],
   "source": [
    "dataPath = os.path.join(dir_path, '../data')\n",
    "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "# Load decode Input\n",
    "decInputFile = os.path.join(dataPath, 'decode_input.txt')\n",
    "with open(decInputFile, 'r') as f:\n",
    "    inData = f.read().splitlines()\n",
    "    inX = np.asarray(inData[0:12800], dtype = np.float)     # input is 100 letters @ 128 = 12800, or 0-12799. NOTE: Recall Python slice is [).\n",
    "    inW = np.asarray(inData[12800:16128], dtype = np.float) # wieths are 26 * 128 = 3328, or 12800-16127\n",
    "    inT = np.asarray(inData[16128:], dtype = np.float)      # The remaing are the transition probs.\n",
    "print(\"Done reading! Sizes are X: {}, W:{},T: {}\".format(inX.shape, inW.shape, inT.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reshaping! Sizes now are X: (100, 128), W:(128, 26),T: (26, 26)\n"
     ]
    }
   ],
   "source": [
    "# Reshape arrays\n",
    "# Reshape T to 26x26\n",
    "inT = np.reshape(inT,(26,26)) \n",
    "inX = np.reshape(inX, (-1,128))\n",
    "inW = np.reshape(inW, (128,-1))\n",
    "print(\"Done reshaping! Sizes now are X: {}, W:{},T: {}\".format(inX.shape, inW.shape, inT.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shapes: sequence: (100, 128), weights: (128, 26), T matrix:(26, 26)\n",
      "[7.78442958e-03 1.52115672e-02 1.20710706e-02 4.69876271e-03\n",
      " 5.34670451e-01 1.14755986e-02 5.64371856e-02 3.31816960e-02\n",
      " 4.00406494e-03 1.53669183e-01 4.88480308e-01 4.30666478e-05\n",
      " 3.11189330e-01 7.07851358e-02 6.51891449e-02 1.29705870e-01\n",
      " 1.68724845e-03 4.50357985e-01 6.23706302e-02 3.08509408e-03\n",
      " 2.69362883e-02 3.39592362e-01 2.16999483e-01 3.78132364e-02\n",
      " 1.30214979e-02 2.69906264e-01] (26,) (26,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max-Sum algorithm!\n",
    "def crf_decoder(seq, w, t):\n",
    "    # Init\n",
    "    seqLen  = seq.shape[0]\n",
    "    dataLen = w.shape[1]\n",
    "    cMat    = np.zeros((seqLen, dataLen))\n",
    "    bMat    = np.matmul(seq, w) # this gives the probability of observing each i standalone\n",
    "    maxIdx  = np.zeros((seqLen, dataLen), dtype = np.int)\n",
    "    decSeq  = []\n",
    "    ci = np.zeros((26,26))\n",
    "    \n",
    "    # Get step 0 estimates\n",
    "    step0    = np.matmul(seq[0,:], w)\n",
    "    c1 = np.multiply(step0,t)      # the previous node potential x edje potenital for all i->j pairs\n",
    "    maxIdx[0,:] = np.argmax(c1, axis = 0) #1x26 the max elem indexes\n",
    "    c1 = c1[maxIdx[0,:],range(c1.shape[1])] #1x26 select the max element, as indexed by maxIdx, for every column\n",
    "    cMat[0,:] = c1\n",
    "    print(\"Input shapes: sequence: {}, weights: {}, T matrix:{}\".format(seq.shape,w.shape,t.shape))\n",
    "    \n",
    "    # Perform a pass over steps 1-99 or 2-100 in 1-index notation!\n",
    "    for i in range(1,seqLen):\n",
    "        fi  = bMat[i,:]              # get likelihood of i observation being any letter as standalone \n",
    "        cYi = cMat[i-1,:]            # i-1 step's potential msg to this node i\n",
    "        cYj = np.multiply(fi, t)     # mul the likelihood of each letter with all transition probs.\n",
    "        maxIdx[i,:] = np.argmax(cYj, axis = 0) #1x26 the max elem indexes\n",
    "        cYj = cYj[maxIdx[i,:],range(cYj.shape[1])] #1x26 select the max element, as indexed by maxIdx, for every column\n",
    "        cYj = np.multiply(cYj, cYi)  # multiply current cYj = g_yj->yi* fj with pervious node's(i-1) msgs to yield the msg node i will wend to i+1\n",
    "        if i == 1:\n",
    "            print(cYj, cYj.shape, fi.shape)\n",
    "        #mostProbState = np.matmul(res[i-1,:], t)\n",
    "    #TODO: Perform the backward pass to get most prob sequence\n",
    "        \n",
    "    #labels = np.argmax(s, axis = 1)\n",
    "    #result = [letters[i] for i in labels]\n",
    "    return decSeq\n",
    "    \n",
    "crf_decoder(inX, inW, inT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f', 'p', 'd', 'k', 'j', 'o', 'i', 'u', 'y', 't', 'g', 'j', 'r', 'a', 'v', 'm', 'j', 'm', 's', 'u', 'n', 'h', 'y', 'n', 'p', 'w', 'h', 'm', 'e', 'v', 'j', 'k', 'z', 'p', 'n', 'b', 'i', 'r', 'b', 'z', 'g', 'v', 'm', 'k', 'd', 'd', 'i', 'e', 'x', 'r', 'f', 'e', 'y', 'm', 'm', 'x', 'c', 'o', 'm', 'r', 'x', 'x', 'x', 'n', 'c', 's', 'k', 'v', 'n', 'r', 'u', 'a', 'y', 'o', 'k', 'y', 'r', 'p', 'h', 'l', 'b', 'j', 't', 'w', 'l', 'u', 'w', 'p', 'q', 'a', 'i', 'g', 'r', 'f', 'v', 'u', 'd', 'z', 'a', 'p']\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d601ea375213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mexit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# returns the exit status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmdTest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# returns the exit status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'compute' is not defined"
     ]
    }
   ],
   "source": [
    "# Part 3 Benchamrking with SVM!\n",
    "# Define where svm_hmm lib and executables are\n",
    "libPath = os.path.join(dir_path,'svm_hmm_linux64')\n",
    "learnerPath = os.path.join(libPath, 'svm_hmm_learn')\n",
    "testerPath  = os.path.join(libPath, 'svm_hmm_classify')\n",
    "# data for the svms\n",
    "svmTrainData = os.path.join(dataPath,'train_struct.txt')\n",
    "svmTestData = os.path.join(dataPath,'test_struct.txt')\n",
    "# C parameter for regulirization impact.\n",
    "cParams = [1,2,5,10,100]\n",
    "# array that holds accuracies for all plots. its going to be 2x3x|cParmas| = letter, word-wise accuracy x 3 models x number of examined c Params\n",
    "acc = np.zeros((2,3,len(cParams)))\n",
    "for i,c in enumerate(cParams):\n",
    "    learnOptions = '-c ' +str(c)\n",
    "    svmHmmOutput = 'models/svm_hmm_'+str(c)+'.model'\n",
    "    ## Create a command to call the binaries required\n",
    "    cmd = ' '.join((learnerPath, learnOptions, svmTrainData, svmHmmOutput)) # ./svm_hmm_learn -c 5 -e 0.5 example7/declaration_of_independence.dat declaration.model \n",
    "    outFile = 'results/test_c_'+str(c)+'.outtags' \n",
    "    cmdTest = ' '.join((testerPath, svmTestData, svmHmmOutput, outFile)) \n",
    "    #y, x = lbl.svm_read_problem(svmTrainData, return_scipy = True) # y: ndarray, x: csr_matrix \n",
    "    #m = lbl.train(y[:200], x[:200, :], '-c 4')\n",
    "    exit = os.system(cmd) # returns the exit status\n",
    "    os.system(cmdTest) # returns the exit status\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_letterwise_accuracy(gTruth, pred):\n",
    "    \n",
    "    with open(gTruth, 'r') as g, open(pred, 'r') as p:\n",
    "        predClass = p.read()\n",
    "        trueClass = g.read()\n",
    "    print(trueClass[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_letterwise_accuracy(svmTestData, outFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
